{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "STEP 4: Modeling Fusion"
      ],
      "metadata": {
        "id": "N5oiT_Sml5Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XXkUIKlmAUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load engineered features (already preprocessed)\n",
        "df = pd.read_parquet(\"data_out/features_engineered.parquet\").fillna(0)\n",
        "\n",
        "# EEG / GSR / TIVA / SELFREPORT features\n",
        "eeg_cols  = [c for c in df.columns if \"eeg_\" in c or any(b in c for b in [\"Alpha\",\"Beta\",\"Theta\",\"Gamma\"])]\n",
        "gsr_cols  = [c for c in df.columns if \"gsr_\" in c or \"conductance\" in c.lower()]\n",
        "tiva_cols = [c for c in df.columns if \"tiva_\" in c or \"AU\" in c]\n",
        "sr_cols   = [c for c in df.columns if \"sr_\" in c or \"valence\" in c.lower() or \"arousal\" in c.lower()]\n",
        "\n",
        "# Features and labels\n",
        "X_eeg  = df[eeg_cols].values\n",
        "X_gsr  = df[gsr_cols].values\n",
        "X_tiva = df[tiva_cols].values\n",
        "X_sr   = df[sr_cols].values\n",
        "y      = df[\"_y\"].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Stratified split for each modality\n",
        "X_eeg_train, X_eeg_test, y_train, y_test = train_test_split(X_eeg, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_gsr_train, X_gsr_test, _, _ = train_test_split(X_gsr, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_tiva_train, X_tiva_test, _, _ = train_test_split(X_tiva, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_sr_train, X_sr_test, _, _     = train_test_split(X_sr, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(\"Feature shapes -> EEG:\", X_eeg_train.shape, \"GSR:\", X_gsr_train.shape,\n",
        "      \"TIVA:\", X_tiva_train.shape, \"SELFREPORT:\", X_sr_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWcWJ0ZJpda6",
        "outputId": "491ee4fe-4ebc-471a-863e-3ef1af43158f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shapes -> EEG: (3939, 34) GSR: (3939, 1) TIVA: (3939, 2) SELFREPORT: (3939, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "def clean_features(X):\n",
        "    # Replace NaN, inf, -inf with 0\n",
        "    return np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "# Clean\n",
        "X_eeg_train  = clean_features(X_eeg_train)\n",
        "X_gsr_train  = clean_features(X_gsr_train)\n",
        "X_tiva_train = clean_features(X_tiva_train)\n",
        "X_sr_train   = clean_features(X_sr_train)\n",
        "\n",
        "X_eeg_test  = clean_features(X_eeg_test)\n",
        "X_gsr_test  = clean_features(X_gsr_test)\n",
        "X_tiva_test = clean_features(X_tiva_test)\n",
        "X_sr_test   = clean_features(X_sr_test)\n",
        "\n",
        "# Standardize\n",
        "scaler_eeg  = StandardScaler()\n",
        "scaler_gsr  = StandardScaler()\n",
        "scaler_tiva = StandardScaler()\n",
        "scaler_sr   = StandardScaler()\n",
        "\n",
        "X_eeg_train_scaled  = scaler_eeg.fit_transform(X_eeg_train)\n",
        "X_gsr_train_scaled  = scaler_gsr.fit_transform(X_gsr_train)\n",
        "X_tiva_train_scaled = scaler_tiva.fit_transform(X_tiva_train)\n",
        "X_sr_train_scaled   = scaler_sr.fit_transform(X_sr_train)\n",
        "\n",
        "X_eeg_test_scaled  = scaler_eeg.transform(X_eeg_test)\n",
        "X_gsr_test_scaled  = scaler_gsr.transform(X_gsr_test)\n",
        "X_tiva_test_scaled = scaler_tiva.transform(X_tiva_test)\n",
        "X_sr_test_scaled   = scaler_sr.transform(X_sr_test)\n",
        "\n",
        "print(\"Features cleaned and standardized. Sample mean/std (first 5):\")\n",
        "print(np.mean(X_eeg_train_scaled, axis=0)[:5], np.std(X_eeg_train_scaled, axis=0)[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXyCqIA8n9iI",
        "outputId": "6c96738c-24ef-4025-995f-6ecf90553911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features cleaned and standardized. Sample mean/std (first 5):\n",
            "[-5.39874483e-15  1.03954813e-16 -2.02839071e-15 -1.85149912e-15\n",
            " -1.24015773e-18] [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def train_xgb(X_tr, y_tr, X_te, y_te, modality_name=\"modality\"):\n",
        "    clf = xgb.XGBClassifier(\n",
        "        n_estimators=200, max_depth=5, learning_rate=0.05,\n",
        "        subsample=0.8, colsample_bytree=0.8, random_state=42,\n",
        "        use_label_encoder=False, eval_metric=\"mlogloss\"\n",
        "    )\n",
        "    clf.fit(X_tr, y_tr)\n",
        "    y_pred = clf.predict(X_te)\n",
        "    print(f\"{modality_name} Accuracy:\", accuracy_score(y_te, y_pred))\n",
        "    print(f\"{modality_name} Macro F1:\", f1_score(y_te, y_pred, average=\"macro\"))\n",
        "    return clf\n",
        "\n",
        "# Train each modality\n",
        "clf_eeg   = train_xgb(X_eeg_train_scaled, y_train, X_eeg_test_scaled, y_test, \"EEG\")\n",
        "clf_gsr   = train_xgb(X_gsr_train_scaled, y_train, X_gsr_test_scaled, y_test, \"GSR\")\n",
        "clf_tiva  = train_xgb(X_tiva_train_scaled, y_train, X_tiva_test_scaled, y_test, \"TIVA\")\n",
        "clf_sr    = train_xgb(X_sr_train_scaled, y_train, X_sr_test_scaled, y_test, \"SELFREPORT\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbHRoK-9pjks",
        "outputId": "de827969-71f1-4655-9f0b-f99b1ca859f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:15:56] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EEG Accuracy: 0.6964467005076143\n",
            "EEG Macro F1: 0.32488146773861054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:15:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GSR Accuracy: 0.6873096446700507\n",
            "GSR Macro F1: 0.3174396928998156\n",
            "TIVA Accuracy: 0.6944162436548224\n",
            "TIVA Macro F1: 0.2732174955062912\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:15:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n",
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [15:15:58] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SELFREPORT Accuracy: 0.766497461928934\n",
            "SELFREPORT Macro F1: 0.49965460611175844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predicted probabilities (3 classes) for each modality\n",
        "prob_eeg_train  = clf_eeg.predict_proba(X_eeg_train_scaled)\n",
        "prob_gsr_train  = clf_gsr.predict_proba(X_gsr_train_scaled)\n",
        "prob_tiva_train = clf_tiva.predict_proba(X_tiva_train_scaled)\n",
        "prob_sr_train   = clf_sr.predict_proba(X_sr_train_scaled)\n",
        "\n",
        "prob_eeg_test   = clf_eeg.predict_proba(X_eeg_test_scaled)\n",
        "prob_gsr_test   = clf_gsr.predict_proba(X_gsr_test_scaled)\n",
        "prob_tiva_test  = clf_tiva.predict_proba(X_tiva_test_scaled)\n",
        "prob_sr_test    = clf_sr.predict_proba(X_sr_test_scaled)\n",
        "\n",
        "# Stack horizontally → 3 classes × 4 modalities = 12 features\n",
        "meta_X_train = np.hstack([prob_eeg_train, prob_gsr_train, prob_tiva_train, prob_sr_train])\n",
        "meta_X_test  = np.hstack([prob_eeg_test, prob_gsr_test, prob_tiva_test, prob_sr_test])\n",
        "\n",
        "print(\"Meta-classifier train shape:\", meta_X_train.shape)\n",
        "print(\"Meta-classifier test shape:\", meta_X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdZxjPAuqUNu",
        "outputId": "b4cdece0-94b3-4453-febc-7bc36ab864a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-classifier train shape: (3939, 12)\n",
            "Meta-classifier test shape: (985, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# Convert stacked features to tensors\n",
        "meta_X_train_t = torch.tensor(meta_X_train, dtype=torch.float32)\n",
        "meta_y_train_t = torch.tensor(y_train, dtype=torch.long)\n",
        "meta_X_test_t  = torch.tensor(meta_X_test, dtype=torch.float32)\n",
        "meta_y_test_t  = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(meta_X_train_t, meta_y_train_t)\n",
        "train_loader  = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define simple MLP meta-classifier\n",
        "class MetaClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=12, hidden_dim=16, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\n",
        "    def forward(self, x):\n",
        "        return self.fc2(self.relu(self.fc1(x)))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "meta_model = MetaClassifier().to(device)\n",
        "criterion  = nn.CrossEntropyLoss()\n",
        "optimizer  = torch.optim.Adam(meta_model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    meta_model.train()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        out = meta_model(xb)\n",
        "        loss = criterion(out, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{epochs} Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "meta_model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = meta_model(meta_X_test_t.to(device))\n",
        "    y_pred_meta = torch.argmax(preds, dim=1).cpu().numpy()\n",
        "\n",
        "print(\"Stacking Meta-classifier Accuracy:\", accuracy_score(y_test, y_pred_meta))\n",
        "print(\"Macro F1:\", f1_score(y_test, y_pred_meta, average=\"macro\"))\n",
        "print(classification_report(y_test, y_pred_meta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1g8aUbMryjV",
        "outputId": "f45eb6fc-763a-49ec-9203-0fbec46d072a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/30 Loss: 0.0058\n",
            "Epoch 20/30 Loss: 0.0455\n",
            "Epoch 30/30 Loss: 0.8336\n",
            "Stacking Meta-classifier Accuracy: 0.7147208121827411\n",
            "Macro F1: 0.5111749561851939\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.35      0.19      0.24        43\n",
            "           1       0.78      0.85      0.81       684\n",
            "           2       0.53      0.43      0.48       258\n",
            "\n",
            "    accuracy                           0.71       985\n",
            "   macro avg       0.55      0.49      0.51       985\n",
            "weighted avg       0.69      0.71      0.70       985\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fusion_path = \"models/fusion_model.pt\"\n",
        "torch.save({\n",
        "    \"meta_model_state_dict\": meta_model.state_dict(),\n",
        "    \"clf_eeg\": clf_eeg,\n",
        "    \"clf_gsr\": clf_gsr,\n",
        "    \"clf_tiva\": clf_tiva,\n",
        "    \"clf_sr\": clf_sr,\n",
        "    \"scaler_eeg\": scaler_eeg,\n",
        "    \"scaler_gsr\": scaler_gsr,\n",
        "    \"scaler_tiva\": scaler_tiva,\n",
        "    \"scaler_sr\": scaler_sr\n",
        "}, fusion_path)\n",
        "\n",
        "print(\"Saved fusion model to:\", fusion_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUIY2azCr1gG",
        "outputId": "8d2925ef-7df9-4930-e404-8ddaef0e2e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved fusion model to: models/fusion_model.pt\n"
          ]
        }
      ]
    }
  ]
}