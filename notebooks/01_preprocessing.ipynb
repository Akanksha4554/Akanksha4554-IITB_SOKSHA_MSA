{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "STEP 1: Preprocessing"
      ],
      "metadata": {
        "id": "yVJRu-Mfhe4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libs\n",
        "!pip install --quiet xgboost shap imbalanced-learn streamlit pyngrok tqdm\n",
        "\n",
        "# Mount Drive\n",
        "from google.colab import drive\n",
        "import os, glob\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set dataset path (adjust if your STData sits elsewhere in Drive)\n",
        "DATA_DIR = \"/content/drive/MyDrive/STData/STData\"  # <- change if needed\n",
        "\n",
        "# Quick check\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    raise FileNotFoundError(f\"DATA_DIR not found: {DATA_DIR}. Check path in Drive.\")\n",
        "\n",
        "subjects = sorted([d for d in os.listdir(DATA_DIR) if d.isdigit()], key=lambda x:int(x))\n",
        "print(f\"Found {len(subjects)} subject folders (examples): {subjects[:6]}\")\n",
        "# show example files in first subject\n",
        "if subjects:\n",
        "    print(\"Example files in subject\", subjects[0], \":\", sorted(glob.glob(os.path.join(DATA_DIR, subjects[0], \"*\")) )[:12])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33DFUooVfspT",
        "outputId": "66e82185-d176-406a-f005-4ad18094a916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "Found 38 subject folders (examples): ['1', '2', '3', '4', '5', '6']\n",
            "Example files in subject 1 : ['/content/drive/MyDrive/STData/STData/1/1_BlankScreenData.csv', '/content/drive/MyDrive/STData/STData/1/1_DLOT.xlsx', '/content/drive/MyDrive/STData/STData/1/1_EEG.csv', '/content/drive/MyDrive/STData/STData/1/1_EYE.csv', '/content/drive/MyDrive/STData/STData/1/1_GSR.csv', '/content/drive/MyDrive/STData/STData/1/1_IVT.csv', '/content/drive/MyDrive/STData/STData/1/1_NSTLX.csv', '/content/drive/MyDrive/STData/STData/1/1_PSY.csv', '/content/drive/MyDrive/STData/STData/1/1_TIVA.csv', '/content/drive/MyDrive/STData/STData/1/1_externalEvents.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard imports\n",
        "import numpy as np, pandas as pd, os, math, gc\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import scipy.signal as signal\n",
        "from collections import Counter\n",
        "\n",
        "# sklearn / xgboost\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
        "import xgboost as xgb\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Hyperparams\n",
        "FS = 256                # assumed EEG sample rate (adjust if your data says otherwise)\n",
        "WINDOW_SEC = 5\n",
        "WINDOW_SIZE = FS * WINDOW_SEC\n",
        "STEP_SEC = 5\n",
        "STEP_SIZE = FS * STEP_SEC\n",
        "\n",
        "OUT_DIR = \"data_out\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "MODEL_DIR = \"models\"\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Config:\", dict(FS=FS, WINDOW_SEC=WINDOW_SEC, WINDOW_SIZE=WINDOW_SIZE, STEP_SEC=STEP_SEC, STEP_SIZE=STEP_SIZE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1tEiaLZf0HR",
        "outputId": "f23ed07c-dbd8-4780-f108-9166247c8de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: {'FS': 256, 'WINDOW_SEC': 5, 'WINDOW_SIZE': 1280, 'STEP_SEC': 5, 'STEP_SIZE': 1280}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def read_table(path):\n",
        "    \"\"\"Robustly read csv/xlsx/parquet. Returns empty DataFrame if missing or read fails.\"\"\"\n",
        "    path = str(path)\n",
        "    if not os.path.exists(path):\n",
        "        return pd.DataFrame()\n",
        "    ext = Path(path).suffix.lower()\n",
        "    try:\n",
        "        if ext in [\".csv\", \".txt\"]:\n",
        "            return pd.read_csv(path)\n",
        "        if ext in [\".xls\", \".xlsx\"]:\n",
        "            return pd.read_excel(path)\n",
        "        if ext == \".parquet\":\n",
        "            return pd.read_parquet(path)\n",
        "        return pd.read_csv(path, engine=\"python\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to read {path}: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def find_file_with_prefix(folder, prefix):\n",
        "    \"\"\"Find a file in folder that starts with prefix (prefix includes subject id and underscore).\"\"\"\n",
        "    files = sorted([f for f in os.listdir(folder) if f.startswith(prefix)])\n",
        "    return os.path.join(folder, files[0]) if files else None\n",
        "\n",
        "def window_iter(sig, window_size=WINDOW_SIZE, step=STEP_SIZE):\n",
        "    sig = np.asarray(sig)\n",
        "    n = len(sig)\n",
        "    if n < window_size:\n",
        "        return []\n",
        "    idxs = range(0, n - window_size + 1, step)\n",
        "    return [sig[s:s+window_size] for s in idxs]\n",
        "\n",
        "def eeg_bandpower(sig, fs=FS):\n",
        "    sig = np.asarray(sig, dtype=float)\n",
        "    if sig.size < 4:\n",
        "        return {\"delta\":0.0,\"theta\":0.0,\"alpha\":0.0,\"beta\":0.0,\"gamma\":0.0}\n",
        "    freqs, psd = signal.welch(sig, fs=fs, nperseg=min(len(sig), fs*2))\n",
        "    bands = {\"delta\":(1,4),\"theta\":(4,8),\"alpha\":(8,12),\"beta\":(12,30),\"gamma\":(30,45)}\n",
        "    out = {}\n",
        "    for name,(lo,hi) in bands.items():\n",
        "        mask = (freqs>=lo)&(freqs<=hi)\n",
        "        out[name] = float(np.trapz(psd[mask], freqs[mask])) if mask.sum() else 0.0\n",
        "    return out"
      ],
      "metadata": {
        "id": "qzlWa6rCf3Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_eeg_windows(eeg_df):\n",
        "    \"\"\"Return list of dicts; each dict is features for one window.\"\"\"\n",
        "    if eeg_df is None or eeg_df.empty:\n",
        "        return []\n",
        "    # Attempt to find band columns first (like Alpha_..). Fallback to RAW channels.\n",
        "    band_cols = [c for c in eeg_df.columns if any(b in c.lower() for b in [\"delta\",\"theta\",\"alpha\",\"beta\",\"gamma\"])]\n",
        "    if len(band_cols) > 0:\n",
        "        per_col_windows = {}\n",
        "        for c in band_cols:\n",
        "            sig = pd.to_numeric(eeg_df[c], errors=\"coerce\").dropna().values\n",
        "            per_col_windows[c] = window_iter(sig)\n",
        "        # ensure at least one column had windows\n",
        "        lens = [len(v) for v in per_col_windows.values()]\n",
        "        if not lens or min(lens)==0:\n",
        "            return []\n",
        "        nwin = min(lens)\n",
        "        windows = []\n",
        "        for i in range(nwin):\n",
        "            row = {}\n",
        "            for c in band_cols:\n",
        "                seg = per_col_windows[c][i]\n",
        "                row[f\"{c}_mean\"] = float(np.mean(seg)) if len(seg)>0 else 0.0\n",
        "                row[f\"{c}_std\"]  = float(np.std(seg)) if len(seg)>0 else 0.0\n",
        "            windows.append(row)\n",
        "        return windows\n",
        "    else:\n",
        "        # find raw EEG channel columns\n",
        "        raw_cols = [c for c in eeg_df.columns if c.lower().startswith(\"raw_\") or any(ch in c.lower() for ch in [\"tp9\",\"af7\",\"af8\",\"tp10\",\"fp1\",\"fp2\",\"f3\",\"f4\"])]\n",
        "        if len(raw_cols) == 0:\n",
        "            return []\n",
        "        per_col_windows={}\n",
        "        for c in raw_cols:\n",
        "            sig = pd.to_numeric(eeg_df[c], errors=\"coerce\").dropna().values\n",
        "            per_col_windows[c] = window_iter(sig)\n",
        "        lens = [len(v) for v in per_col_windows.values()]\n",
        "        if not lens or min(lens)==0:\n",
        "            return []\n",
        "        nwin = min(lens)\n",
        "        windows=[]\n",
        "        for i in range(nwin):\n",
        "            row={}\n",
        "            for c in raw_cols:\n",
        "                seg = per_col_windows[c][i]\n",
        "                bp = eeg_bandpower(seg)\n",
        "                for band,val in bp.items():\n",
        "                    row[f\"{c}_{band}\"] = float(val)\n",
        "            windows.append(row)\n",
        "        return windows\n",
        "\n",
        "def extract_gsr_windows(gsr_df):\n",
        "    if gsr_df is None or gsr_df.empty:\n",
        "        return []\n",
        "    candidate = None\n",
        "    for c in gsr_df.columns:\n",
        "        if \"conductance\" in c.lower() or \"gsr\" in c.lower() or \"eda\" in c.lower():\n",
        "            candidate = c; break\n",
        "    # fallback to first numeric column if none matched\n",
        "    if candidate is None:\n",
        "        numeric_cols = [c for c in gsr_df.columns if pd.api.types.is_numeric_dtype(gsr_df[c])]\n",
        "        if numeric_cols:\n",
        "            candidate = numeric_cols[0]\n",
        "        else:\n",
        "            return []\n",
        "    sig = pd.to_numeric(gsr_df[candidate], errors=\"coerce\").dropna().values\n",
        "    segs = window_iter(sig)\n",
        "    out=[]\n",
        "    for w in segs:\n",
        "        out.append({\n",
        "            f\"{candidate}_mean\": float(np.mean(w)),\n",
        "            f\"{candidate}_std\": float(np.std(w)),\n",
        "            f\"{candidate}_peaks\": int(np.sum(np.diff(w) > 0.05 * max(1.0, np.max(np.abs(w)))))\n",
        "        })\n",
        "    return out\n",
        "\n",
        "def extract_tiva_windows(tiva_df, n_windows):\n",
        "    if tiva_df is None or tiva_df.empty:\n",
        "        return [ {} for _ in range(n_windows) ]\n",
        "    # drop obvious meta columns but keep AUs/emotion cols\n",
        "    meta_cols = set([\"UnixTime\",\"Row\",\"QuestionKey\",\"Timestamp\",\"SampleNumber\",\"Sample_Index\"])\n",
        "    cols = [c for c in tiva_df.columns if c not in meta_cols]\n",
        "    if len(cols) == 0:\n",
        "        return [ {} for _ in range(n_windows) ]\n",
        "    stats = {}\n",
        "    for c in cols:\n",
        "        vals = pd.to_numeric(tiva_df[c], errors=\"coerce\").dropna().values\n",
        "        stats[f\"{c}_mean\"] = float(vals.mean()) if vals.size>0 else 0.0\n",
        "        stats[f\"{c}_std\"]  = float(vals.std())  if vals.size>0 else 0.0\n",
        "    # broadcast same summary across windows (TIVA often lower-rate)\n",
        "    return [dict(stats) for _ in range(max(1, n_windows))]"
      ],
      "metadata": {
        "id": "jmCj3bItf6Jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verdict_to_class(v):\n",
        "    \"\"\"Map various label formats to 0/1/2. Adjust heuristics as dataset dictates.\"\"\"\n",
        "    if pd.isna(v):\n",
        "        return 0\n",
        "    s = str(v).strip().lower()\n",
        "    if s in [\"positive\",\"pos\",\"+\",\"1\",\"true\",\"yes\",\"correct\"]:\n",
        "        return 1\n",
        "    if s in [\"negative\",\"neg\",\"-\",\"-1\",\"false\",\"no\",\"incorrect\"]:\n",
        "        return 2\n",
        "    # try numeric\n",
        "    try:\n",
        "        vi = float(s)\n",
        "        if vi > 0: return 1\n",
        "        if vi < 0: return 2\n",
        "        return 0\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "def build_windows_for_subject(sid):\n",
        "    subj_dir = os.path.join(DATA_DIR, str(sid))\n",
        "    # find files by prefix robustly\n",
        "    eeg_fp = find_file_with_prefix(subj_dir, f\"{sid}_EEG\")\n",
        "    gsr_fp = find_file_with_prefix(subj_dir, f\"{sid}_GSR\")\n",
        "    tiva_fp = find_file_with_prefix(subj_dir, f\"{sid}_TIVA\")\n",
        "    psy_fp = find_file_with_prefix(subj_dir, f\"{sid}_PSY\")\n",
        "    # read\n",
        "    eeg = read_table(eeg_fp) if eeg_fp else pd.DataFrame()\n",
        "    gsr = read_table(gsr_fp) if gsr_fp else pd.DataFrame()\n",
        "    tiva = read_table(tiva_fp) if tiva_fp else pd.DataFrame()\n",
        "    psy = read_table(psy_fp) if psy_fp else pd.DataFrame()\n",
        "\n",
        "    rows = []\n",
        "    if psy.empty:\n",
        "        # no PSY file: cannot extract trial labels -> skip\n",
        "        print(f\"⚠️ subject {sid}: missing or empty PSY ({psy_fp})\")\n",
        "        return rows\n",
        "\n",
        "    # try to infer trial id column names in PSY\n",
        "    possible_key_cols = [c for c in psy.columns if c.lower() in (\"key\",\"trial\",\"questionkey\",\"question\",\"trialid\",\"question_id\")]\n",
        "    possible_label_cols = [c for c in psy.columns if c.lower() in (\"verdict\",\"label\",\"sentiment\",\"score\",\"response\",\"rating\",\"valence\")]\n",
        "    # choose best column\n",
        "    key_col = possible_key_cols[0] if possible_key_cols else None\n",
        "    label_col = possible_label_cols[0] if possible_label_cols else None\n",
        "\n",
        "    if key_col is None:\n",
        "        # fallback: iterate rows with index as key\n",
        "        psy[\"_key_fallback\"] = psy.index.astype(str)\n",
        "        key_col = \"_key_fallback\"\n",
        "    if label_col is None:\n",
        "        # fallback: try any numeric column or the last column\n",
        "        numeric = [c for c in psy.columns if pd.api.types.is_numeric_dtype(psy[c])]\n",
        "        label_col = numeric[0] if numeric else psy.columns[-1]\n",
        "\n",
        "    for _, trial in psy.iterrows():\n",
        "        qkey = trial.get(key_col, None)\n",
        "        label_raw = trial.get(label_col, None)\n",
        "        label = verdict_to_class(label_raw)\n",
        "\n",
        "        # filter signals by QuestionKey if present, otherwise use whole file\n",
        "        if \"QuestionKey\" in eeg.columns:\n",
        "            eeg_trial = eeg[eeg[\"QuestionKey\"] == qkey]\n",
        "        else:\n",
        "            eeg_trial = eeg\n",
        "        if \"QuestionKey\" in gsr.columns:\n",
        "            gsr_trial = gsr[gsr[\"QuestionKey\"] == qkey]\n",
        "        else:\n",
        "            gsr_trial = gsr\n",
        "        if \"QuestionKey\" in tiva.columns:\n",
        "            tiva_trial = tiva[tiva[\"QuestionKey\"] == qkey]\n",
        "        else:\n",
        "            tiva_trial = tiva\n",
        "\n",
        "        # extract windows\n",
        "        eeg_w = extract_eeg_windows(eeg_trial)\n",
        "        gsr_w = extract_gsr_windows(gsr_trial)\n",
        "        n_windows = max(len(eeg_w), len(gsr_w), 1)\n",
        "        tiva_w = extract_tiva_windows(tiva_trial, n_windows)\n",
        "\n",
        "        # combine windows\n",
        "        for i in range(n_windows):\n",
        "            r = {}\n",
        "            if i < len(eeg_w): r.update(eeg_w[i])\n",
        "            if i < len(gsr_w): r.update(gsr_w[i])\n",
        "            if i < len(tiva_w): r.update(tiva_w[i])\n",
        "            r[\"_subject\"] = sid\n",
        "            r[\"_trial\"] = str(qkey)\n",
        "            r[\"_win\"] = int(i)\n",
        "            r[\"_y\"] = int(label)\n",
        "            rows.append(r)\n",
        "    return rows"
      ],
      "metadata": {
        "id": "K6Rzr7UggAYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows = []\n",
        "for sid in tqdm(subjects, desc=\"Building windows\"):\n",
        "    try:\n",
        "        out = build_windows_for_subject(sid)\n",
        "        if len(out) == 0:\n",
        "            # print minimal info but don't spam\n",
        "            print(f\"Subject {sid}: 0 windows\")\n",
        "        rows.extend(out)\n",
        "    except Exception as e:\n",
        "        print(\"Error processing subject\", sid, \":\", e)\n",
        "\n",
        "features_windows = pd.DataFrame(rows)\n",
        "print(\"Built windows dataset shape:\", features_windows.shape)\n",
        "if not features_windows.empty:\n",
        "    print(\"Columns sample:\", features_windows.columns.tolist()[:30])\n",
        "    print(\"Label distribution:\", features_windows[\"_y\"].value_counts().to_dict())\n",
        "else:\n",
        "    print(\"⚠️ No windows extracted. Inspect the prints above for missing PSY or files.\")\n",
        "\n",
        "# Save for later\n",
        "if not features_windows.empty:\n",
        "    features_windows = features_windows.fillna(0)\n",
        "    features_windows.to_parquet(os.path.join(OUT_DIR, \"features_windows.parquet\"), index=False)\n",
        "    print(\"Saved features to:\", os.path.join(OUT_DIR, \"features_windows.parquet\"))\n",
        "else:\n",
        "    features_windows.to_parquet(os.path.join(OUT_DIR, \"features_windows.parquet\"), index=False)\n",
        "    print(\"Saved empty dataframe to:\", os.path.join(OUT_DIR, \"features_windows.parquet\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV7kBcT0gDaq",
        "outputId": "1ec2cae6-9f4c-4594-ca3d-a764124f6786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rBuilding windows:   0%|          | 0/38 [00:00<?, ?it/s]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:   3%|▎         | 1/38 [00:07<04:27,  7.22s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:   5%|▌         | 2/38 [00:15<04:51,  8.10s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:185: RuntimeWarning: invalid value encountered in subtract\n",
            "  x = asanyarray(arr - arrmean)\n",
            "Building windows:   8%|▊         | 3/38 [00:25<04:59,  8.55s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  11%|█         | 4/38 [00:32<04:36,  8.13s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  13%|█▎        | 5/38 [00:41<04:36,  8.38s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  16%|█▌        | 6/38 [00:47<04:09,  7.78s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  18%|█▊        | 7/38 [00:56<04:12,  8.13s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  21%|██        | 8/38 [01:01<03:34,  7.16s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  26%|██▋       | 10/38 [01:14<03:03,  6.56s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  29%|██▉       | 11/38 [01:23<03:15,  7.23s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  32%|███▏      | 12/38 [01:31<03:10,  7.32s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  34%|███▍      | 13/38 [01:39<03:09,  7.59s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  37%|███▋      | 14/38 [01:47<03:07,  7.82s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  39%|███▉      | 15/38 [01:53<02:46,  7.23s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  42%|████▏     | 16/38 [02:01<02:43,  7.44s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  45%|████▍     | 17/38 [02:10<02:45,  7.90s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  47%|████▋     | 18/38 [02:19<02:48,  8.41s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  50%|█████     | 19/38 [02:29<02:44,  8.65s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  53%|█████▎    | 20/38 [02:36<02:26,  8.13s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  55%|█████▌    | 21/38 [02:44<02:21,  8.33s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  58%|█████▊    | 22/38 [02:54<02:19,  8.74s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  61%|██████    | 23/38 [03:03<02:12,  8.84s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  63%|██████▎   | 24/38 [03:11<02:01,  8.65s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  66%|██████▌   | 25/38 [03:21<01:57,  9.05s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  68%|██████▊   | 26/38 [03:29<01:43,  8.65s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  71%|███████   | 27/38 [03:37<01:31,  8.35s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  74%|███████▎  | 28/38 [03:47<01:29,  8.95s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  76%|███████▋  | 29/38 [03:57<01:22,  9.16s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  79%|███████▉  | 30/38 [04:04<01:09,  8.68s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  82%|████████▏ | 31/38 [04:10<00:53,  7.68s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  84%|████████▍ | 32/38 [04:18<00:47,  7.91s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  87%|████████▋ | 33/38 [04:26<00:40,  8.01s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  89%|████████▉ | 34/38 [04:35<00:32,  8.20s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  92%|█████████▏| 35/38 [04:41<00:23,  7.69s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2,40) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  95%|█████████▍| 36/38 [04:50<00:15,  7.90s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows:  97%|█████████▋| 37/38 [04:58<00:07,  7.99s/it]/tmp/ipython-input-32232327.py:11: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  return pd.read_csv(path)\n",
            "Building windows: 100%|██████████| 38/38 [05:05<00:00,  8.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built windows dataset shape: (4924, 125)\n",
            "Columns sample: ['Delta_TP9_mean', 'Delta_TP9_std', 'Delta_AF7_mean', 'Delta_AF7_std', 'Delta_AF8_mean', 'Delta_AF8_std', 'Delta_TP10_mean', 'Delta_TP10_std', 'Theta_TP9_mean', 'Theta_TP9_std', 'Theta_AF7_mean', 'Theta_AF7_std', 'Theta_AF8_mean', 'Theta_AF8_std', 'Theta_TP10_mean', 'Theta_TP10_std', 'Alpha_TP9_mean', 'Alpha_TP9_std', 'Alpha_AF7_mean', 'Alpha_AF7_std', 'Alpha_AF8_mean', 'Alpha_AF8_std', 'Alpha_TP10_mean', 'Alpha_TP10_std', 'Beta_TP9_mean', 'Beta_TP9_std', 'Beta_AF7_mean', 'Beta_AF7_std', 'Beta_AF8_mean', 'Beta_AF8_std']\n",
            "Label distribution: {1: 3422, 2: 1288, 0: 214}\n",
            "Saved features to: data_out/features_windows.parquet\n"
          ]
        }
      ]
    }
  ]
}